{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import feature files and load them to a FeatureMap() file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Determination of memory status is not supported on this \n",
      " platform, measuring for memoryleaks will never fail\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import glob\n",
    "from pyopenms import *\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path= \"results/GNPSexport/interim/\"\n",
    "isExist= os.path.exists(path)\n",
    "if not isExist:\n",
    "    os.mkdir(path)\n",
    "\n",
    "input_feature_files = glob.glob('results/features/interim/*.featureXML')\n",
    "feature_maps = []\n",
    "for featurexml_file in input_feature_files:\n",
    "    fmap = FeatureMap()\n",
    "    FeatureXMLFile().load(featurexml_file, fmap)\n",
    "    feature_maps.append(fmap)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. MapAlignmentAlgorithmPoseClustering algorithm is used to align the retention time shifts caused by chromatographic differences. \n",
    "The reference file used for Map Alignment is the feature map with the highest number of features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ref_index = [i[0] for i in sorted(enumerate([fm.size() for fm in feature_maps]), key=lambda x:x[1])][-1]\n",
    "\n",
    "aligner = MapAlignmentAlgorithmPoseClustering()\n",
    "aligner_par= aligner.getDefaults()\n",
    "\n",
    "aligner_par.setValue(\"max_num_peaks_considered\", -1)\n",
    "aligner_par.setValue(\"superimposer:mz_pair_max_distance\", 0.05)\n",
    "aligner_par.setValue(\"pairfinder:distance_MZ:max_difference\", 10.0)\n",
    "aligner_par.setValue(\"pairfinder:distance_MZ:unit\", \"ppm\")\n",
    "aligner.setParameters(aligner_par)\n",
    "aligner.setReference(feature_maps[ref_index])\n",
    "\n",
    "for feature_map in feature_maps[:ref_index] + feature_maps[ref_index+1:]:\n",
    "    trafo = TransformationDescription()\n",
    "    aligner.align(feature_map, trafo)\n",
    "    transformer = MapAlignmentTransformer()\n",
    "    transformer.transformRetentionTimes(feature_map, trafo, True) # store original RT as meta value\n",
    "\n",
    "for feature_map in feature_maps:    \n",
    "    feature_file = os.path.join(\"results\", \"\", \"GNPSexport\", \"\", \"interim\", \"\", 'MapAligned_' + os.path.basename(feature_map.getMetaValue('spectra_data')[0].decode())[7:-5] +\".featureXML\")\n",
    "    trafo_file= os.path.join(\"results\", \"\", \"GNPSexport\", \"\", \"interim\", \"\", 'MapAligned_' + os.path.basename(feature_map.getMetaValue('spectra_data')[0].decode())[7:-5] +\".trafoXML\")\n",
    "    FeatureXMLFile().store(feature_file, feature_map)\n",
    "    TransformationXMLFile().store(trafo_file, trafo)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import aligned feature files and load them to a FeatureMap() file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_feature_files = sorted(glob.glob(\"results/GNPSexport/interim/MapAligned*.featureXML\"))\n",
    "\n",
    "feature_maps = []\n",
    "for featurexml_file in input_feature_files:\n",
    "    fmap = FeatureMap()\n",
    "    FeatureXMLFile().load(featurexml_file, fmap)\n",
    "    feature_maps.append(fmap)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. IDMapper annotates MS2 fragmentations as peptide/protein identifications. This is the only way to currently annotate MS2 data for GNPS FBMN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "use_centroid_rt= False\n",
    "use_centroid_mz= True\n",
    "protein_ids = []\n",
    "peptide_ids= []\n",
    "\n",
    "mapper = IDMapper()\n",
    "\n",
    "input_mzml_files= sorted(glob.glob(\"results/interim/PCpeak_*.mzML\"))\n",
    "\n",
    "for filename in input_mzml_files:\n",
    "    exp = MSExperiment()\n",
    "    MzMLFile().load(filename, exp)\n",
    "\n",
    "    for fmap in feature_maps:\n",
    "        if os.path.basename(fmap.getMetaValue('spectra_data')[0].decode()) == os.path.basename(filename):\n",
    "            peptide_ids = []\n",
    "            protein_ids = []\n",
    "            \n",
    "            mapper.annotate(fmap, peptide_ids, protein_ids, use_centroid_rt, use_centroid_mz, exp)\n",
    "        featureidx_file = os.path.join(\"results\", \"\", \"GNPSexport\", \"\", \"interim\", \"\", 'IDMapper_' + os.path.basename(fmap.getMetaValue('spectra_data')[0].decode())[7:-5] +\".featureXML\")\n",
    "        FeatureXMLFile().store(featureidx_file, fmap)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import the annotated feature files and load them in a FeatureMap() file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_feature_files = sorted(glob.glob('results/GNPSexport/interim/IDMapper*.featureXML'))\n",
    "\n",
    "feature_maps = []\n",
    "for featurexml_file in input_feature_files:\n",
    "    fmap = FeatureMap()\n",
    "    FeatureXMLFile().load(featurexml_file, fmap)\n",
    "    feature_maps.append(fmap)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. The Feature Grouping Algorithm is used to aggregate the feature information (from single files) into a ConsensusFeature, linking features from different files together, which have a smiliar m/z and rt (MS1 level)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_grouper = FeatureGroupingAlgorithmKD()\n",
    "\n",
    "consensus_map = ConsensusMap()\n",
    "file_descriptions = consensus_map.getColumnHeaders()\n",
    "\n",
    "for i, feature_map in enumerate(feature_maps):\n",
    "    file_description = file_descriptions.get(i, ColumnHeader())\n",
    "    file_description.filename = feature_map.getMetaValue('spectra_data')[0].decode()\n",
    "    file_description.size = feature_map.size()\n",
    "    file_descriptions[i] = file_description\n",
    "\n",
    "feature_grouper.group(feature_maps, consensus_map)\n",
    "consensus_map.setColumnHeaders(file_descriptions)\n",
    "\n",
    "\n",
    "Consensus_file= os.path.join(\"results\", \"\", \"GNPSexport\", \"\",\"interim\", \"\", 'consensus' + \".consensusXML\")\n",
    "ConsensusXMLFile().store(Consensus_file, consensus_map)\n",
    "\n",
    "\n",
    "# get intensities as a DataFrame\n",
    "intensities = consensus_map.get_intensity_df()\n",
    "\n",
    "# get meta data as DataFrame\n",
    "meta_data = consensus_map.get_metadata_df()[['RT', 'mz', 'charge']]\n",
    "\n",
    "# you can concatenate these two for a \"result\" DataFrame\n",
    "result = pd.concat([meta_data, intensities], axis=1)\n",
    "\n",
    "# if you don't need labeled index, remove it (and/or save with index = False)\n",
    "result.reset_index(drop=True, inplace=True)\n",
    "\n",
    "# store as tsv file\n",
    "result.to_csv('results/GNPSexport/interim/consensus.tsv', sep = '\\t', index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. File-filtering is used to remove all features that do not have an MS2 spectrum."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_consensus= \"results/GNPSexport/interim/consensus.consensusXML\"\n",
    "cmap = ConsensusMap()\n",
    "ConsensusXMLFile().load(input_consensus, cmap)\n",
    "new_map= ConsensusMap(cmap)\n",
    "new_map.clear(False)\n",
    "for f in cmap:\n",
    "    if f.getPeptideIdentifications() !=[]:\n",
    "        new_map.push_back(f)\n",
    "        \n",
    "Consensus_file= os.path.join(\"results\", \"\", \"GNPSexport\", \"\", \"interim\", \"\",'filtered' + \".consensusXML\")\n",
    "ConsensusXMLFile().store(Consensus_file, new_map)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5. Convert the ConsensusXML file to a FeatureQuantificationTable.txt file compatible to GNPS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     #CONSENSUS  charge_cf       rt_cf       mz_cf  quality_cf  width_cf  \\\n",
      "0     CONSENSUS          1  301.766906  393.223249    0.000445       NaN   \n",
      "1     CONSENSUS          1  141.660936  379.207529    0.000307       NaN   \n",
      "2     CONSENSUS          1   79.132486  254.161193    0.003703       NaN   \n",
      "3     CONSENSUS          1  526.656072  460.269339    0.002016       NaN   \n",
      "4     CONSENSUS          1  151.911141  328.139078    0.001595       NaN   \n",
      "...         ...        ...         ...         ...         ...       ...   \n",
      "7046  CONSENSUS          1  491.720961  858.608860    0.000010       NaN   \n",
      "7047  CONSENSUS          1  210.843145  226.089659    0.000046       NaN   \n",
      "7048  CONSENSUS          2  111.798745  301.168825    0.000030       NaN   \n",
      "7049  CONSENSUS          1  144.365028  450.255977    0.000009       NaN   \n",
      "7050  CONSENSUS          1  364.415148  380.218136    0.000024       NaN   \n",
      "\n",
      "      intensity_0  intensity_1  intensity_2  intensity_3  ...  intensity_26  \\\n",
      "0       7443680.0   13535850.0   13423620.0   14076760.0  ...     8191838.0   \n",
      "1       3699400.0   10704690.0    9434231.0    8763564.0  ...     2665060.0   \n",
      "2     121834096.0  114376000.0  137001200.0  136163504.0  ...    38975220.0   \n",
      "3      22398310.0   13234580.0   24078230.0   21137250.0  ...    59390640.0   \n",
      "4      36532420.0   55908592.0   53082512.0   45685432.0  ...    24493060.0   \n",
      "...           ...          ...          ...          ...  ...           ...   \n",
      "7046          0.0          0.0          0.0          0.0  ...           0.0   \n",
      "7047          0.0          0.0          0.0          0.0  ...           0.0   \n",
      "7048          0.0          0.0          0.0          0.0  ...           0.0   \n",
      "7049          0.0          0.0          0.0          0.0  ...           0.0   \n",
      "7050          0.0          0.0          0.0          0.0  ...           0.0   \n",
      "\n",
      "      intensity_27  intensity_28  intensity_29  intensity_30  intensity_31  \\\n",
      "0        4805972.0     2208030.0     8551499.0     2792170.0  1.300701e+06   \n",
      "1        4790689.0     1402128.0     2388590.0     2700853.0  9.040833e+05   \n",
      "2       24628190.0   124948096.0    45881760.0    25535300.0  1.113518e+08   \n",
      "3         889642.5    59286840.0    77973608.0    57287048.0  2.155392e+07   \n",
      "4       15264430.0    12603810.0    24240750.0    23348760.0  6.652861e+06   \n",
      "...            ...           ...           ...           ...           ...   \n",
      "7046           0.0           0.0           0.0           0.0  0.000000e+00   \n",
      "7047           0.0           0.0           0.0           0.0  0.000000e+00   \n",
      "7048           0.0           0.0           0.0           0.0  0.000000e+00   \n",
      "7049           0.0           0.0           0.0           0.0  0.000000e+00   \n",
      "7050           0.0           0.0           0.0           0.0  0.000000e+00   \n",
      "\n",
      "      intensity_32  intensity_33  intensity_34  intensity_35  \n",
      "0     1.068605e+07     3491061.0     2621669.0  1.005787e+07  \n",
      "1     2.952004e+06     2980725.0     1733681.0  3.621176e+06  \n",
      "2     4.295983e+07    16987770.0   144671200.0  4.539911e+07  \n",
      "3     6.404618e+05    38911720.0    23264860.0  5.474964e+07  \n",
      "4     1.758404e+07    10452810.0    14051800.0  2.678875e+07  \n",
      "...            ...           ...           ...           ...  \n",
      "7046  0.000000e+00           0.0           0.0  2.532333e+05  \n",
      "7047  0.000000e+00           0.0           0.0  1.619512e+06  \n",
      "7048  0.000000e+00           0.0           0.0  1.002554e+06  \n",
      "7049  0.000000e+00           0.0           0.0  3.391787e+05  \n",
      "7050  0.000000e+00           0.0           0.0  8.230814e+05  \n",
      "\n",
      "[7051 rows x 42 columns]\n"
     ]
    }
   ],
   "source": [
    "input_consensus= \"results/GNPSexport/interim/filtered.consensusXML\"\n",
    "cmap = ConsensusMap()\n",
    "ConsensusXMLFile().load(input_consensus, cmap)\n",
    "\n",
    "# get intensities as a DataFrame\n",
    "intensities = cmap.get_intensity_df()\n",
    "\n",
    "# get meta data as DataFrame\n",
    "meta_data = cmap.get_metadata_df()\n",
    "\n",
    "# you can concatenate these two for a \"result\" DataFrame\n",
    "result = pd.concat([meta_data, intensities], axis=1)\n",
    "\n",
    "# if you don't need labeled index, remove it (and/or save with index = False)\n",
    "result.reset_index(drop=True, inplace=True)\n",
    "\n",
    "idx = 0\n",
    "new_col = \"CONSENSUS\"  # can be a list, a Series, an array or a scalar   \n",
    "result.insert(loc=idx, column='#CONSENSUS', value=new_col)   \n",
    "result= result.rename(columns= {\"charge\": \"charge_cf\", \"RT\": \"rt_cf\", \"mz\": \"mz_cf\", \"quality\": \"quality_cf\", \"width\": \"width_cf\"})\n",
    "result= result.drop([\"sequence\"], axis= 1)\n",
    "result= result.sort_index(axis=1)\n",
    "\n",
    "filemeta= cmap.getColumnHeaders()\n",
    "mapIDs = [k for k in filemeta.keys()]\n",
    "filename= []\n",
    "size=[]\n",
    "label= []\n",
    "for header in filemeta.values():\n",
    "    files= header.filename\n",
    "    sizes= header.size\n",
    "    labels= header.label\n",
    "    filename.append(files)\n",
    "    size.append(sizes)\n",
    "    label.append(labels)\n",
    "\n",
    "dict = {'id': mapIDs, 'filename': filename,'label': label,'size': size}\n",
    "DF= pd.DataFrame(dict)\n",
    "DF[\"id\"] = \"intensity_\"+ (DF[\"id\"]).astype(str)\n",
    "\n",
    "cols= result.columns\n",
    "for col in cols:\n",
    "    for i, path in enumerate(filename):\n",
    "        if path== col:\n",
    "            name= DF[\"id\"][i]\n",
    "            result.rename(columns={col: name}, inplace=True)\n",
    "\n",
    "cols = result.columns\n",
    "preordered = [\"#CONSENSUS\", \"charge_cf\", \"rt_cf\", \"mz_cf\", \"quality_cf\", \"width_cf\"]\n",
    "new_cols = preordered + [c for c in result.columns if c not in preordered]\n",
    "new_df = result.reindex(columns=new_cols)\n",
    "new_df.to_csv('results/GNPSexport/FeatureQuantificationTable.txt', sep = '\\t', index = False)\n",
    "print(new_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "edde62aa2661007f0756e9790e7a328c288a583bf6ce768a355147dac67c8db8"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 64-bit ('pyopenms': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
