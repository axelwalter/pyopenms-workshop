{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b008d44c",
   "metadata": {},
   "source": [
    "# `Preprocessing workflow`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52d77bcb",
   "metadata": {},
   "source": [
    "Import libraries:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f80b6832",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyopenms import *\n",
    "import os\n",
    "import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fd0b726a",
   "metadata": {},
   "outputs": [],
   "source": [
    "path= \"results/interim\"\n",
    "if not os.path.exists(path):\n",
    "    os.mkdir(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f88f0df5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1) Feature Detection\n",
    "\n",
    "input_mzml_files = glob.glob('Example_data/*.mzML')\n",
    "\n",
    "# 1.1) Mass trace detection\n",
    "\n",
    "for filename in input_mzml_files:\n",
    "    print(\"Mass Trace Detection: \", filename)\n",
    "    exp = MSExperiment()\n",
    "    MzMLFile().load(filename, exp)\n",
    "    exp.sortSpectra(True)\n",
    "    mass_traces = []\n",
    "    mtd = MassTraceDetection()\n",
    "    mtd_par = mtd.getDefaults()\n",
    "    mtd_par.setValue(\"mass_error_ppm\", 10.0) \n",
    "    mtd_par.setValue(\"noise_threshold_int\", 1.0e04)\n",
    "    mtd.setParameters(mtd_par)\n",
    "    mtd.run(exp, mass_traces, 0)\n",
    "\n",
    "# 1.2) Elution peak detection\n",
    "    print(\"Elution Peak Detection: \", filename)\n",
    "    mass_traces_split = []\n",
    "    mass_traces_final = []\n",
    "    epd = ElutionPeakDetection()\n",
    "    epd_par = epd.getDefaults()\n",
    "    epd_par.setValue(\"width_filtering\", \"fixed\")\n",
    "    epd.setParameters(epd_par)\n",
    "    epd.detectPeaks(mass_traces, mass_traces_split)\n",
    "     \n",
    "    if (epd.getParameters().getValue(\"width_filtering\") == \"auto\"):\n",
    "          epd.filterByPeakWidth(mass_traces_split, mass_traces_final)\n",
    "    else:\n",
    "          mass_traces_final = mass_traces_split\n",
    "\n",
    "# 1.3) Feature detection\n",
    "    print(\"Feature Detection: \", filename)\n",
    "    feature_map_FFM = FeatureMap()\n",
    "    feat_chrom = []\n",
    "    ffm = FeatureFindingMetabo()\n",
    "    ffm_par = ffm.getDefaults() \n",
    "    ffm_par.setValue(\"isotope_filtering_model\", \"none\")\n",
    "    ffm_par.setValue(\"remove_single_traces\", \"true\")\n",
    "    ffm_par.setValue(\"mz_scoring_by_elements\", \"false\")\n",
    "    ffm_par.setValue(\"report_convex_hulls\", \"true\")\n",
    "    ffm.setParameters(ffm_par)\n",
    "    ffm.run(mass_traces_final, feature_map_FFM, feat_chrom)\n",
    "    feature_map_FFM.setUniqueIds()\n",
    "    feature_map_FFM.setPrimaryMSRunPath([filename.encode()])\n",
    "    print(filename[7:-5] + \".featureXML\")\n",
    "    FeatureXMLFile().store(os.path.join(path, os.path.basename(filename)[:-5] + \".featureXML\"), feature_map_FFM)\n",
    "    \n",
    "print(\"Finished Feature Detection\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41ddd154",
   "metadata": {},
   "source": [
    "Display the features in a dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33b01270",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_feature_files = sorted(glob.glob('results/interim/*.featureXML'))\n",
    "\n",
    "for filename in input_feature_files:\n",
    "    fmap = FeatureMap()\n",
    "    FeatureXMLFile().load(filename, fmap)\n",
    "    DF= fmap.get_df(export_peptide_identifications=False)\n",
    "    feature_csv= os.path.join(\"results\", \"features\", 'features_' + os.path.basename(filename)[4:-10] +\"csv\")\n",
    "    DF.to_csv(feature_csv)\n",
    "print(\"example:\", os.path.basename(filename))\n",
    "display(DF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6efd8231",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2) Map alignment \n",
    "\n",
    "feature_maps=[]\n",
    "\n",
    "for filename in input_feature_files:\n",
    "    feature_map_MFD = FeatureMap()\n",
    "    FeatureXMLFile().load(filename, feature_map_MFD)\n",
    "    feature_maps.append(feature_map_MFD)\n",
    "\n",
    "ref_index = [i[0] for i in sorted(enumerate([fm.size() for fm in feature_maps]), key=lambda x:x[1])][-1]\n",
    "\n",
    "aligner = MapAlignmentAlgorithmPoseClustering()\n",
    "aligner_par= aligner.getDefaults()\n",
    "\n",
    "aligner_par.setValue(\"max_num_peaks_considered\", -1)\n",
    "aligner_par.setValue(\"superimposer:mz_pair_max_distance\", 0.05)\n",
    "aligner_par.setValue(\"pairfinder:distance_MZ:max_difference\", 10.0)\n",
    "aligner_par.setValue(\"pairfinder:distance_MZ:unit\", \"ppm\")\n",
    "aligner.setParameters(aligner_par)\n",
    "aligner.setReference(feature_maps[ref_index])\n",
    "\n",
    "for feature_map in feature_maps[:ref_index] + feature_maps[ref_index+1:]:\n",
    "    trafo = TransformationDescription()\n",
    "    aligner.align(feature_map, trafo)\n",
    "    transformer = MapAlignmentTransformer()\n",
    "    transformer.transformRetentionTimes(feature_map, trafo, True) # store original RT as meta value\n",
    "\n",
    "for feature_map in feature_maps:    \n",
    "    feature_file = os.path.join(path, 'Aligned_' + os.path.basename(feature_map.getMetaValue('spectra_data')[0].decode())[:-5] +\".featureXML\")\n",
    "    FeatureXMLFile().store(feature_file, feature_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b3be55cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3) Feature grouping\n",
    "\n",
    "input_feature_files = sorted(glob.glob('results/interim/Aligned_*.featureXML'))\n",
    "\n",
    "feature_maps = []\n",
    "for featurexml_file in input_feature_files:\n",
    "    fmap = FeatureMap()\n",
    "    FeatureXMLFile().load(featurexml_file, fmap)\n",
    "    feature_maps.append(fmap)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b827315c",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_grouper = FeatureGroupingAlgorithmKD()\n",
    "\n",
    "consensus_map = ConsensusMap()\n",
    "file_descriptions = consensus_map.getColumnHeaders()\n",
    "\n",
    "for i, feature_map in enumerate(feature_maps):\n",
    "    file_description = file_descriptions.get(i, ColumnHeader())\n",
    "    file_description.filename = os.path.basename(feature_map.getMetaValue('spectra_data')[0].decode())[7:]\n",
    "    file_description.size = feature_map.size()\n",
    "    file_descriptions[i] = file_description\n",
    "\n",
    "feature_grouper.group(feature_maps, consensus_map)\n",
    "consensus_map.setColumnHeaders(file_descriptions)\n",
    "\n",
    "\n",
    "Consensus_file= os.path.join(path, 'consensus' + \".consensusXML\")\n",
    "ConsensusXMLFile().store(Consensus_file, consensus_map)\n",
    "\n",
    "\n",
    "# get intensities as a DataFrame\n",
    "result = consensus_map.get_df()\n",
    "result= result.reset_index()\n",
    "result= result.drop(columns= [\"sequence\"])\n",
    "# store as tsv file\n",
    "result.to_csv('results/FeatureMatrix.tsv', sep = '\\t', index = False)\n",
    "result"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "edde62aa2661007f0756e9790e7a328c288a583bf6ce768a355147dac67c8db8"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
